{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1 - import files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path = 'datasets/'\n",
    "\n",
    "class_csv = pd.read_csv(path + 'class.csv', sep=';')\n",
    "test_level = pd.read_csv(path + 'test_level.csv', sep=';')\n",
    "test = pd.read_csv(path + 'test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2 - check files correctness \n",
    "\n",
    "# Select only rows with integer id\n",
    "test = test[test['student_id'].apply(lambda x: str(x).isdigit())]\n",
    "test = test[test['class_id'].apply(lambda x: str(x).isdigit())]\n",
    "test = test[test['test_level_id'].apply(lambda x: str(x).isdigit())]\n",
    "test = test[test['licence_id'].apply(lambda x: str(x).isdigit())]\n",
    "\n",
    "# Clear empty overall_score and authorized_at rows\n",
    "test = test[test['test_status'].notna()]\n",
    "test = test[test['authorized_at'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Task 3 - prepare test_utilization.csv\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Transform date ie. 06.07.18 11:37 to 2018-07-06 (YY-MM-DD format)\n",
    "def adjust_format_to_date(row):\n",
    "    dd_c = datetime.datetime.strptime(row['test_created_at'][:8],'%d.%m.%y')\n",
    "    dd_a = datetime.datetime.strptime(row['test_authorized_at'][:8],'%d.%m.%y')\n",
    "    dd_c = str(dd_c.year) + '-' + '%02d' % dd_c.month + '-' + '%02d' % dd_c.day\n",
    "    dd_a = str(dd_a.year) + '-' + '%02d' % dd_a.month + '-' + '%02d' % dd_a.day\n",
    "    return dd_c, dd_a\n",
    "\n",
    "# Get 'name' and 'teaching hours' from class_csv\n",
    "def get_name(row):\n",
    "    desired_row = class_csv[class_csv['id'] == row['class_id']]\n",
    "    return desired_row.values[0][3], desired_row.values[0][6]\n",
    "    \n",
    "# Copy from test desired columns in test_utilization.csv and sort by 'class_id'\n",
    "df = test.sort_values(by = ['class_id'])\n",
    "df = df[['class_id','created_at','authorized_at','test_level_id']]\n",
    "df.columns = ['class_id', 'test_created_at','test_authorized_at','test_level']\n",
    "\n",
    "# Change 'test_created_at' and 'test_authorized_at' date format\n",
    "df[['test_created_at', 'test_authorized_at']] = df.apply(adjust_format_to_date, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Take class 'name' and 'teaching hours' from class_csv\n",
    "df[['class_name', 'teaching_hours']] = df.apply(get_name, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Enumerate test_id from 1 to the range of data frame\n",
    "df['test_id'] = np.arange(1, df.shape[0]+1)\n",
    "\n",
    "# Make class_test_number\n",
    "df['class_test_number'] = df.groupby('class_id').cumcount()+1\n",
    "\n",
    "# Sort columns to desired order\n",
    "test_utilization = df[['class_id', 'class_name', 'teaching_hours', 'test_id', 'test_created_at', 'test_authorized_at', 'test_level', 'class_test_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mgr/lib/python3.7/site-packages/pandas/core/reshape/merge.py:617: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "### Task 4 - prepare test_average_scores.csv\n",
    "\n",
    "# Take idx of test marked as SCORING_SCORED\n",
    "df = test[test['test_status'] == 'SCORING_SCORED']\n",
    "df = df[['class_id', 'created_at', 'authorized_at', 'overall_score']]\n",
    "df.columns = ['class_id', 'test_created_at', 'test_authorized_at', 'overall_score']\n",
    "\n",
    "# Change 'test_created_at' and 'test_authorized_at' date format\n",
    "df[['test_created_at', 'test_authorized_at']] = df.apply(adjust_format_to_date, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Take the earliest/latest date from particular class (creation date/final authorization date)\n",
    "min_date = df.groupby(['class_id']).agg({'test_created_at': [np.min]})\n",
    "max_date = df.groupby(['class_id']).agg({'test_authorized_at': [np.max]})\n",
    "\n",
    "# Calculate avg_class_test_overall_score\n",
    "avg_score = df[['class_id','overall_score']].groupby('class_id').mean().round(2)\n",
    "\n",
    "# Join avg_class_test_overall_score with min_date and max_date \n",
    "avg_score = avg_score.join(min_date).join(max_date)\n",
    "avg_score = avg_score.reset_index()\n",
    "avg_score.columns = ['class_id', 'avg_class_test_overall_score', 'test_created_at', 'test_authorized_at']\n",
    "\n",
    "# Take class 'name' and 'teaching hours' from class_csv\n",
    "avg_score[['class_name', 'teaching_hours']] = avg_score.apply(get_name, axis=1, result_type=\"expand\")\n",
    "\n",
    "# Sort columns to desired order\n",
    "avg_score = avg_score[['class_id', 'class_name', 'teaching_hours', 'test_created_at', 'test_authorized_at', 'avg_class_test_overall_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 5 - Save dataframes to the csv\n",
    "\n",
    "test_utilization.to_csv(path + 'test_utilization.csv')\n",
    "avg_score.to_csv(path + 'test_average_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class_id            class_name teaching_hours test_created_at  \\\n",
      "0           1             QA Sanity           6-10      2018-07-06   \n",
      "1           5  new tell app release            3-5      2018-07-13   \n",
      "2           6               0.6.0.0            1-3      2018-07-18   \n",
      "3           8                DCtest          11-15      2018-07-26   \n",
      "4          10               0.7.0.0            3-5      2018-08-02   \n",
      "..        ...                   ...            ...             ...   \n",
      "438       647                   7-B            3-5      2019-04-23   \n",
      "439       648                   7-C            3-5      2019-04-23   \n",
      "440       649                   7-D            3-5      2019-04-23   \n",
      "441       650                   7-E            3-5      2019-04-23   \n",
      "442       652        ID-ALI-STEP UP            1-3      2019-04-25   \n",
      "\n",
      "    test_authorized_at  avg_class_test_overall_score  \n",
      "0           2018-07-06                         16.50  \n",
      "1           2018-07-13                         17.00  \n",
      "2           2018-07-18                         21.00  \n",
      "3           2019-01-31                         24.00  \n",
      "4           2018-08-02                         11.00  \n",
      "..                 ...                           ...  \n",
      "438         2019-04-24                         27.53  \n",
      "439         2019-04-24                         29.53  \n",
      "440         2019-04-24                         29.55  \n",
      "441         2019-04-24                         28.44  \n",
      "442         2019-04-25                         41.00  \n",
      "\n",
      "[443 rows x 6 columns]\n",
      "       class_id            class_name teaching_hours  test_id test_created_at  \\\n",
      "0             1             QA Sanity           6-10        1      2018-07-06   \n",
      "1             1             QA Sanity           6-10        2      2018-07-06   \n",
      "2             1             QA Sanity           6-10        3      2018-07-06   \n",
      "3             5  new tell app release            3-5        4      2018-07-13   \n",
      "4             5  new tell app release            3-5        5      2018-07-13   \n",
      "...         ...                   ...            ...      ...             ...   \n",
      "11415       650                   7-E            3-5    11416      2019-04-23   \n",
      "11416       650                   7-E            3-5    11417      2019-04-23   \n",
      "11417       650                   7-E            3-5    11418      2019-04-23   \n",
      "11418       652        ID-ALI-STEP UP            1-3    11419      2019-04-25   \n",
      "11419       653              Pinnacle            1-3    11420      2019-04-29   \n",
      "\n",
      "      test_authorized_at  test_level  class_test_number  \n",
      "0             2018-07-06           1                  1  \n",
      "1             2018-07-06           1                  2  \n",
      "2             2018-07-06           1                  3  \n",
      "3             2018-07-13           1                  1  \n",
      "4             2018-07-13           1                  2  \n",
      "...                  ...         ...                ...  \n",
      "11415         2019-04-24           4                 13  \n",
      "11416         2019-04-24           4                 14  \n",
      "11417         2019-04-24           3                 15  \n",
      "11418         2019-04-25           5                  1  \n",
      "11419         2019-04-29           2                  1  \n",
      "\n",
      "[11420 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "### Task 6 - Save datasets to DB tables\n",
    "\n",
    "import pandas as pd \n",
    "import sqlite3\n",
    "\n",
    "# Read csv files\n",
    "df_avg_score = pd.read_csv(path + 'test_average_scores.csv')\n",
    "df_test_util = pd.read_csv(path + 'test_utilization.csv')\n",
    "\n",
    "# Drop redundant idx column\n",
    "df_avg_score = df_avg_score.loc[:, df_avg_score.columns != 'Unnamed: 0']\n",
    "df_test_util = df_test_util.loc[:, df_test_util.columns != 'Unnamed: 0']\n",
    "\n",
    "# Take column names \n",
    "columns_avg = str(tuple(df_avg_score.columns.values))\n",
    "columns_util = str(tuple(df_test_util.columns.values))\n",
    "\n",
    "# Make database connection\n",
    "con = sqlite3.connect(\":memory:\") \n",
    "cur = con.cursor()\n",
    "\n",
    "# Create dedicated tables - each for one csv.\n",
    "cur.execute(\"CREATE TABLE avg_score \" + columns_avg + \";\") \n",
    "cur.execute(\"CREATE TABLE columns_util \" + columns_util + \";\") \n",
    "\n",
    "# Insert data into sqlite database\n",
    "df_avg_score.to_sql('avg_score', con, if_exists='append', index=False)\n",
    "df_test_util.to_sql('columns_util', con, if_exists='append', index=False)\n",
    "\n",
    "# See db result - unconment below 2 lines \n",
    "print(pd.read_sql_query(\"SELECT * FROM avg_score\", con))\n",
    "print(pd.read_sql_query(\"SELECT * FROM columns_util\", con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert error [8, 23, 'Class 1A', '15+', '2018-08-19', '2018-12-20', 18.4]\n"
     ]
    }
   ],
   "source": [
    "### Task 7 - unit testing\n",
    "\n",
    "from pandas.util.testing import assert_frame_equal, assert_series_equal, assert_index_equal\n",
    "from task2 import check_files_correctness \n",
    "import pandas as pd\n",
    "import unittest\n",
    "\n",
    "class DFTests(unittest.TestCase):\n",
    "\n",
    "    def setUp(self, filename, path):\n",
    "        \"\"\" Check set up of the csv \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(path + filename, sep = ';')\n",
    "            \n",
    "        except IOError:\n",
    "            print ('Cannot open the file')\n",
    "            \n",
    "        self.fixture = data\n",
    "\n",
    "    def check_NaN_filtering(self):\n",
    "        \"\"\" Check if function in task2 clear the dataset in a proper way \"\"\"        \n",
    "        empty_df = pd.DataFrame([],columns = ['id', 'student_id', 'class_id',  'created_at',  'updated_at', 'last_event_time',  'overall_score', 'test_status',\t'institution_id', 'authorized_at', 'confidence_level',  'speaking_score', 'writing_score',  'reading_score',  'listening_score',  'test_level_id',  'licence_id'])\n",
    "\n",
    "        # Test few cases of data filtering from task2  \n",
    "        case1 = check_files_correctness(self.fixture.iloc[2:3,])\n",
    "        case2 = check_files_correctness(self.fixture.iloc[3:4,:])\n",
    "        case3 = check_files_correctness(self.fixture.iloc[37:38,])\n",
    "        case4 = check_files_correctness(self.fixture.iloc[41:42,])\n",
    "    \n",
    "        # If left != right rise an error\n",
    "        assert_frame_equal(case3, self.fixture.iloc[37:38,])\n",
    "        #assert_frame_equal(case3, self.fixture.iloc[37:38,])\n",
    "        #assert_frame_equal(case3, self.fixture.iloc[37:38,])\n",
    "        #assert_frame_equal(case3, self.fixture.iloc[37:38,])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Filename which opening will be tested\n",
    "    filename, path =  'test.csv', 'datasets/'\n",
    "\n",
    "    # Test part \n",
    "    DFTests.setUp(unittest, filename, path)\n",
    "    DFTests.check_NaN_filtering(unittest)\n",
    "\n",
    "    print(\"Test finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
